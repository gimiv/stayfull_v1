# Developer Handoff: F-002.1 Data Extraction & Enrichment

**Priority**: P0 - BLOCKING F-003
**Effort**: 35 hours (~5 days)
**Parent**: F-002 AI Onboarding Agent
**Specification**: `.architect/features/F-002.1_DATA_EXTRACTION.md`
**Status**: Ready for Implementation
**Deadline**: ASAP (blocks all downstream work)

---

## ðŸš¨ CRITICAL: This is Blocking Work

**You cannot proceed to F-003 until this is 100% complete.**

F-003 (Dynamic Commerce Engine) depends on rich, AI-extracted data from F-002. Without data extraction working, F-003 has nothing to build websites with.

---

## ðŸ“‹ Task Breakdown

### Phase 1: Google Places Integration (12 hours)

#### Task 1.1: Set Up Google Places Client (2 hours)

**File to create:** `apps/ai_agent/services/google_places_service.py`

**Checklist:**
- [ ] Install `googlemaps` package: `pip install googlemaps`
- [ ] Add to `requirements.txt`
- [ ] Get Google Places API key (ask product owner if needed)
- [ ] Add to `.env`: `GOOGLE_PLACES_API_KEY=...`
- [ ] Add to `config/settings/base.py`: `GOOGLE_PLACES_API_KEY = env('GOOGLE_PLACES_API_KEY', default='')`
- [ ] Create `GooglePlacesService` class
- [ ] Initialize `googlemaps.Client` in `__init__`

**Acceptance:**
- [ ] Import works: `from apps.ai_agent.services.google_places_service import GooglePlacesService`
- [ ] Client initializes without errors

#### Task 1.2: Implement Hotel Search (4 hours)

**File:** `apps/ai_agent/services/google_places_service.py`

**Method to implement:**
```python
def search_hotel(self, hotel_name: str, city: str, state: str = None) -> Optional[Dict]:
    """
    Search for hotel and return detailed info.

    See F-002.1 spec section 1.3 for full implementation.
    """
```

**Checklist:**
- [ ] Implement `search_hotel()` method
- [ ] Query format: `"{hotel_name}, {city}, {state}"`
- [ ] Use `self.client.places(query=..., type="lodging")`
- [ ] Get first result's `place_id`
- [ ] Call `self.client.place(place_id=..., fields=[...])` for details
- [ ] Return standardized dict (see spec 1.3)
- [ ] Handle API errors gracefully (return None)
- [ ] Add logging for debugging

**Test Cases:**
```python
# Test with real hotels
service = GooglePlacesService()

# Test 1: Sunset Villa, Miami
result = service.search_hotel("Sunset Villa", "Miami", "FL")
assert result is not None
assert "address" in result
assert "phone" in result

# Test 2: Hotel not found
result = service.search_hotel("Fake Hotel That Doesnt Exist", "Nowhere", "XX")
assert result is None  # Should gracefully return None
```

**Acceptance:**
- [ ] Successfully finds 5/5 test hotels (different cities)
- [ ] Returns all required fields (name, address, phone, location, photos)
- [ ] Returns None for non-existent hotels
- [ ] No exceptions thrown

#### Task 1.3: Implement Timezone Lookup (2 hours)

**File:** `apps/ai_agent/services/google_places_service.py`

**Method to implement:**
```python
def infer_timezone_from_location(self, lat: float, lng: float) -> str:
    """
    Get timezone from GPS coordinates.
    Uses Google Maps Timezone API.
    """
```

**Checklist:**
- [ ] Use `self.client.timezone(location=(lat, lng))`
- [ ] Return `timeZoneId` (e.g., "America/New_York")
- [ ] Default to "America/New_York" if API fails
- [ ] Add error handling

**Test Cases:**
```python
# Miami coordinates
tz = service.infer_timezone_from_location(25.7617, -80.1918)
assert tz == "America/New_York"

# Los Angeles coordinates
tz = service.infer_timezone_from_location(34.0522, -118.2437)
assert tz == "America/Los_Angeles"
```

**Acceptance:**
- [ ] Correct timezone for 5 test coordinates
- [ ] Handles errors without crashing

#### Task 1.4: Integrate into NoraAgent (4 hours)

**File:** `apps/ai_agent/services/nora_agent.py`

**Changes needed:**

1. **Import GooglePlacesService:**
```python
from .google_places_service import GooglePlacesService
```

2. **Initialize in __init__:**
```python
def __init__(self, user, organization):
    # ... existing code ...
    self.google_places = GooglePlacesService()
```

3. **Call in conversation flow:**

When user provides hotel name + city (but NO website), call Google Places:

```python
def _handle_data_provision(self, user_message: str, engine: OnboardingEngine) -> Dict:
    # ... existing extraction logic ...

    # If we have hotel name + city but no website, use Google Places
    if extracted.get('hotel_name') and extracted.get('city') and not extracted.get('website'):
        places_data = self.google_places.search_hotel(
            hotel_name=extracted['hotel_name'],
            city=extracted['city'],
            state=extracted.get('state')
        )

        if places_data:
            # Store for confirmation
            self.context.task_state['_places_data_pending'] = places_data
            self.context.task_state['_awaiting_places_confirmation'] = True
            self.context.save()

            return {
                "message": f"I found {places_data['name']} on Google:\n\n"
                           f"ðŸ“ {places_data['address']}\n"
                           f"ðŸ“ž {places_data.get('phone', 'No phone listed')}\n\n"
                           f"Is this your hotel?",
                "data": {"places_data": places_data},
                "action": "confirm_places_data"
            }
```

4. **Handle confirmation:**
```python
# In process_message(), after address confirmation check:
if self.context.task_state.get('_awaiting_places_confirmation'):
    return self._handle_places_confirmation(user_message)

def _handle_places_confirmation(self, user_message: str) -> Dict:
    """User confirms Google Places data."""
    # Detect intent (confirm/deny)
    intent = self._detect_confirmation_intent(user_message)

    if "CONFIRM" in intent:
        places_data = self.context.task_state.get('_places_data_pending', {})

        # Apply Google Places data to task_state
        self.context.task_state.update({
            'hotel_name': places_data.get('name'),
            'full_address': places_data.get('address'),
            'phone': places_data.get('phone'),
            'website': places_data.get('website'),
            'latitude': places_data['location'].get('lat'),
            'longitude': places_data['location'].get('lng'),
            'google_place_id': places_data.get('place_id'),
            'timezone': self.google_places.infer_timezone_from_location(
                places_data['location']['lat'],
                places_data['location']['lng']
            )
        })

        # Parse address into components
        self._parse_address(places_data.get('address'))

        # Clear flags
        self.context.task_state['_awaiting_places_confirmation'] = False
        del self.context.task_state['_places_data_pending']
        self.context.save()

        return {
            "message": "Perfect! Now let's talk about your rooms...",
            "data": {},
            "action": "continue"
        }
```

**Acceptance:**
- [ ] Conversation asks "What's your hotel name and city?"
- [ ] User says "Sunset Villa, Miami FL"
- [ ] Nora calls Google Places automatically
- [ ] Shows confirmation with address + phone
- [ ] User confirms
- [ ] Data stored in task_state
- [ ] Timezone set correctly
- [ ] Test with 3 different hotels

---

### Phase 2: Website Scraping Fix (8 hours)

#### Task 2.1: Fix Integration into Conversation (3 hours)

**File:** `apps/ai_agent/services/nora_agent.py`

**Current problem:** `_handle_website_url()` exists but doesn't properly integrate scraped data.

**What to fix:**

1. **Make sure website URL triggers scraping:**
```python
def _handle_onboarding_message(self, user_message: str) -> Dict:
    # ... existing code ...

    # Detect if message contains URL
    if self.intent_detector.contains_url(user_message):
        return self._handle_website_url(user_message, engine)
```

2. **Complete the `_handle_website_url()` method:**

See spec section 2.2 "Fix 1" for full implementation.

Key additions:
- [ ] Call `self.data_extractor.extract_from_website(url)`
- [ ] Handle extraction errors (fallback to manual Q&A)
- [ ] Store all extracted fields in `task_state`
- [ ] Enrich with Google Places (GPS, timezone)
- [ ] Apply smart defaults
- [ ] Show confirmation message

**Acceptance:**
- [ ] User provides website URL
- [ ] Scraping triggers automatically
- [ ] All extracted fields stored correctly
- [ ] Google Places enrichment works
- [ ] User sees confirmation: "I pulled everything from {url}"

#### Task 2.2: Improve Extraction Prompt (3 hours)

**File:** `apps/ai_agent/services/data_extractor.py`

**Method:** `extract_from_website()`

**Current problem:** GPT-4o prompt too vague, low extraction accuracy.

**What to fix:**

Replace the current extraction prompt with the improved version in spec section 2.2 "Fix 2".

Key improvements:
- [ ] More specific field instructions
- [ ] Clear rules for what to extract
- [ ] Better examples
- [ ] Confidence scoring

**Test Cases:**

Test with these real websites (or similar):
1. Simple HTML site
2. WordPress site
3. Wix/Squarespace site
4. Custom React SPA
5. Hotel chain site

Target: **80%+ extraction accuracy** (gets 8/10 required fields)

**Acceptance:**
- [ ] Test 10 different hotel websites
- [ ] Measure extraction accuracy (% of required fields found)
- [ ] Accuracy â‰¥80% on average
- [ ] All extractions logged for debugging

#### Task 2.3: Error Handling & Logging (2 hours)

**File:** `apps/ai_agent/services/data_extractor.py`

**Add robust error handling:**

```python
def extract_from_website(self, url: str) -> dict:
    """
    Extract hotel data from website.
    Returns dict with extracted data OR {"error": "reason"}
    """
    try:
        # Fetch HTML
        html_content = self._fetch_html(url)
        if not html_content:
            logger.warning(f"Failed to fetch HTML from {url}")
            return {"error": "Could not access website", "confidence": 0.0}

        # Parse with BeautifulSoup
        text_content = self._parse_html(html_content)
        if not text_content:
            logger.warning(f"No text content extracted from {url}")
            return {"error": "Website has no readable content", "confidence": 0.0}

        # Extract with GPT-4o
        extracted = self._extract_with_gpt(text_content)

        # Log extraction results
        logger.info(f"Website extraction from {url}:")
        logger.info(f"  - Confidence: {extracted.get('confidence', 0)}")
        logger.info(f"  - Fields found: {len([k for k, v in extracted.items() if v])}")
        logger.info(f"  - Hotel name: {extracted.get('hotel_name', 'NOT FOUND')}")

        return extracted

    except requests.RequestException as e:
        logger.error(f"Network error fetching {url}: {str(e)}")
        return {"error": f"Network error: {str(e)}", "confidence": 0.0}

    except Exception as e:
        logger.error(f"Unexpected error extracting from {url}: {str(e)}", exc_info=True)
        return {"error": f"Extraction failed: {str(e)}", "confidence": 0.0}
```

**Acceptance:**
- [ ] All errors logged with context
- [ ] No unhandled exceptions
- [ ] Graceful degradation to manual Q&A

---

### Phase 3: Smart Defaults (4 hours)

#### Task 3.1: Implement Smart Defaults (3 hours)

**File:** `apps/ai_agent/services/data_extractor.py`

**Method to add:**
```python
def infer_smart_defaults(self, country: str, state: str = None, city: str = None) -> Dict:
    """
    Infer currency, tax rate, language from location.
    See spec section 3.3 for full implementation.
    """
```

**Checklist:**
- [ ] Create `currency_map` dict (20+ countries)
- [ ] Create `us_tax_rates` dict (50 states)
- [ ] Return dict with currency, tax_rate, language
- [ ] Default to USD, 10% tax if unknown

**Data to include:**

Currency map:
```python
currency_map = {
    'United States': 'USD', 'US': 'USD', 'USA': 'USD',
    'Canada': 'CAD',
    'United Kingdom': 'GBP', 'UK': 'GBP',
    'France': 'EUR', 'Germany': 'EUR', 'Spain': 'EUR', 'Italy': 'EUR',
    'Mexico': 'MXN',
    'Australia': 'AUD',
    'Japan': 'JPY',
    'China': 'CNY',
    'India': 'INR',
    'Brazil': 'BRL',
    # Add more as needed
}
```

US state tax rates (hotel + local average):
```python
us_tax_rates = {
    'AL': 10.0, 'AK': 5.0, 'AZ': 10.8, 'AR': 12.6, 'CA': 10.5,
    'CO': 10.4, 'CT': 15.0, 'DE': 8.0, 'FL': 13.0, 'GA': 13.0,
    'HI': 14.4, 'ID': 9.0, 'IL': 11.6, 'IN': 12.0, 'IA': 12.0,
    'KS': 11.3, 'KY': 11.3, 'LA': 14.0, 'ME': 9.5, 'MD': 11.5,
    'MA': 11.7, 'MI': 11.0, 'MN': 13.9, 'MS': 12.2, 'MO': 12.5,
    'MT': 7.0, 'NE': 12.5, 'NV': 13.4, 'NH': 9.0, 'NJ': 13.6,
    'NM': 12.9, 'NY': 14.8, 'NC': 12.8, 'ND': 12.0, 'OH': 14.5,
    'OK': 13.5, 'OR': 11.5, 'PA': 11.4, 'RI': 13.0, 'SC': 12.1,
    'SD': 10.0, 'TN': 15.3, 'TX': 17.0, 'UT': 12.3, 'VT': 10.0,
    'VA': 10.8, 'WA': 15.6, 'WV': 12.0, 'WI': 13.4, 'WY': 10.0
}
```

**Acceptance:**
- [ ] Returns correct currency for 10 test countries
- [ ] Returns correct tax rate for 10 test states
- [ ] Defaults sensibly for unknown locations

#### Task 3.2: Integrate into Conversation (1 hour)

**File:** `apps/ai_agent/services/nora_agent.py`

**Add this after location data is collected:**

```python
def _apply_smart_defaults(self):
    """
    Apply smart defaults after location is known.
    Called after website scraping or Google Places lookup.
    """
    country = self.context.task_state.get('country')
    state = self.context.task_state.get('state')
    city = self.context.task_state.get('city')

    if country:
        defaults = self.data_extractor.infer_smart_defaults(country, state, city)
        self.context.task_state.update(defaults)
        self.context.save()

        logger.info(f"Applied smart defaults: {defaults}")
```

Call this in `_handle_website_url()` and `_handle_places_confirmation()`.

**Acceptance:**
- [ ] Defaults applied automatically after location known
- [ ] User never sees currency/tax questions
- [ ] Defaults can be edited in Review step

---

### Phase 4: Content Enhancement (6 hours)

#### Task 4.1: Fix Room Description Enhancement (3 hours)

**File:** `apps/ai_agent/services/content_formatter.py`

**Method:** `enhance_room_description()`

**Current problem:** Not being called automatically, prompt could be better.

**What to fix:**

1. **Improve the prompt** (see spec section 4.3)

2. **Call it automatically in DataGenerator:**

**File:** `apps/ai_agent/services/data_generator.py`

```python
def _create_room_types(self, hotel: Hotel, field_values: dict) -> list:
    # ... existing code that creates room types ...

    # After creating room type, enhance description:
    if room_type.description:
        enhanced = self.content_formatter.enhance_room_description(
            basic_description=room_type.description,
            room_name=room_type.name,
            hotel_context={
                'hotel_name': hotel.name,
                'city': hotel.city,
                'amenities': hotel.amenities or []
            }
        )
        room_type.description = enhanced
        room_type.save()
```

**Acceptance:**
- [ ] Every room type gets enhanced description
- [ ] Quality is Airbnb-level
- [ ] Length is 2-3 sentences
- [ ] Test with 10 different room types

#### Task 4.2: Add Hotel Description Generation (2 hours)

**File:** `apps/ai_agent/services/content_formatter.py`

**New method:**
```python
def generate_hotel_description(self, hotel_name: str, city: str, state: str = None) -> str:
    """
    Generate a compelling hotel description if user didn't provide one.
    """
    location = f"{city}, {state}" if state else city

    prompt = f"""
You are writing a hotel description for a booking website.

Hotel Name: {hotel_name}
Location: {location}

Write a 2-3 sentence hotel description that:
1. Captures the essence of the location
2. Highlights what makes this hotel special (infer from name + location)
3. Uses inviting, warm language
4. Avoids clichÃ©s
5. Focuses on guest experience

Style: Airbnb-level quality.

Write ONLY the description (no quotes):
"""

    response = self.client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=150
    )

    return response.choices[0].message.content.strip()
```

**Call in DataGenerator:**
```python
# If hotel description is missing, generate one
if not hotel.description:
    hotel.description = self.content_formatter.generate_hotel_description(
        hotel_name=hotel.name,
        city=hotel.city,
        state=hotel.state
    )
    hotel.save()
```

**Acceptance:**
- [ ] Generated descriptions are high quality
- [ ] Test with 5 different hotels
- [ ] Descriptions are contextually appropriate

#### Task 4.3: Testing (1 hour)

**Test suite:**
```python
# Test with various inputs
inputs = [
    ("Nice room with bed", "Standard Queen", {"hotel_name": "Test Hotel", "city": "Miami"}),
    ("Luxury suite", "Ocean View Suite", {"hotel_name": "Beach Resort", "city": "Malibu"}),
    ("Basic room", "Budget Room", {"hotel_name": "Motel 6", "city": "Phoenix"}),
]

for basic, room_name, context in inputs:
    enhanced = formatter.enhance_room_description(basic, room_name, context)
    print(f"Input: {basic}")
    print(f"Output: {enhanced}\n")
    # Manual review: is quality good?
```

**Acceptance:**
- [ ] All test cases produce quality descriptions
- [ ] No generic/clichÃ©d language
- [ ] Appropriate to the hotel context

---

### Phase 5: Testing & Polish (5 hours)

#### Task 5.1: End-to-End Testing (3 hours)

**Test Scenario 1: Website URL path**
```
1. Start onboarding
2. Provide website URL (e.g., real hotel website)
3. Verify extraction works
4. Verify Google Places enrichment
5. Verify smart defaults applied
6. Complete onboarding
7. Verify hotel created with all data
```

**Test Scenario 2: Hotel name + city path**
```
1. Start onboarding
2. Provide "Sunset Villa, Miami FL"
3. Verify Google Places lookup
4. Verify confirmation dialog
5. Confirm
6. Verify data applied
7. Complete onboarding
8. Verify hotel created
```

**Test Scenario 3: Fallback path**
```
1. Start onboarding
2. Provide fake website that doesn't exist
3. Verify graceful fallback to manual Q&A
4. Answer questions manually
5. Complete onboarding
6. Verify hotel created
```

**Acceptance:**
- [ ] All 3 scenarios complete successfully
- [ ] No crashes or errors
- [ ] Data stored correctly
- [ ] Hotels created in database

#### Task 5.2: Quality Audit (2 hours)

Run the quality test from `.architect/tasks/ONBOARDING_CONVERSATION_QUALITY_TEST.md`

**Target scores:**
- Part 1 (Conversation Flow): 35/40
- Part 2 (Dynamic Data Intelligence): 25/30
- Part 3 (Technical Correctness): 25/30
- **Total: 85/100+**

If score <85, identify issues and fix.

**Acceptance:**
- [ ] Quality audit score â‰¥85/100
- [ ] All P0 features working
- [ ] No critical bugs

---

## âœ… Definition of Done

Before marking F-002.1 complete, verify:

- [ ] **Google Places**: Successfully finds hotels (90%+ success rate)
- [ ] **Website Scraping**: Extracts data (80%+ accuracy)
- [ ] **Smart Defaults**: Automatically sets currency + tax
- [ ] **Content Enhancement**: All descriptions AI-enhanced
- [ ] **End-to-End**: Complete onboarding in <15 minutes
- [ ] **Quality Audit**: Score 85/100+
- [ ] **No P0 Bugs**: Zero critical issues
- [ ] **Documentation**: All code commented
- [ ] **Tests**: All acceptance criteria met
- [ ] **Committed**: All changes in git

**Until ALL checkboxes are checked, F-003 is BLOCKED.**

---

## ðŸ†˜ Getting Unstuck

**If you encounter:**

**Issue**: Google Places API key not working
**Solution**: Ask product owner for valid key with Places API enabled

**Issue**: Website scraping extraction accuracy <80%
**Solution**: Adjust GPT-4o prompt, add more examples, ask architect for review

**Issue**: End-to-end test takes >15 minutes
**Solution**: Review conversation flow, identify redundant questions, optimize

**Issue**: Quality audit score <85
**Solution**: Review failed sections, ask architect for guidance

**Stuck for >2 hours?** â†’ Ask the architect immediately

---

## ðŸ“Š Progress Tracking

Update this daily:

**Day 1:**
- [ ] Phase 1 Tasks 1.1-1.2 complete

**Day 2:**
- [ ] Phase 1 Tasks 1.3-1.4 complete

**Day 3:**
- [ ] Phase 2 complete

**Day 4:**
- [ ] Phase 3 + Phase 4 complete

**Day 5:**
- [ ] Phase 5 complete, F-002.1 DONE

---

**Ready? Let's complete F-002 properly so we can build F-003!**
